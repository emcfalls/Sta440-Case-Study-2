---
title: "women_apparatus_and_individual_all_around_simulation_algo"
subtitle: "no subtitle"
author: "women_apparatus_and_individual_all_around_simulation_algo"
format: 
  html:
    self-contained: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Setup - run this first to get the libraries
```{r setup, include=FALSE}
library(tidyverse)
library(data.table)
library(ggplot2)
library(purrr)
library(dplyr)
library(KernSmooth)
library(parallel)


## LOG INTO https://hypatia.stat.duke.edu USING NET ID AND PW AND THEN CLONE OUR REPO THERE AND THEN RUN THESE SIMULATION .QMD FILES

#flexiblas::flexiblas_load_backend("OPENBLAS-THREADS") |>
 # flexiblas::flexiblas_switch()
  #flexiblas::flexiblas_set_num_threads(8)
```

```{r}
library(parallel)
library(iterators)
library(foreach)
library(doParallel)
library(future)
library(future.apply)

# Use detectCores() to find out how many cores your system has
no_cores <- detectCores() - 1  # Leave one core free for system processes
# Use mclapply to apply a function over a list in parallel
result <- mclapply(1:100, function(x) x^2, mc.cores = no_cores)

no_cores <- detectCores() - 1
registerDoParallel(cores = no_cores)
result <- foreach(i = 1:100) %dopar% {
  i^2
}

plan(multisession, workers = no_cores)
result <- future_lapply(1:100, function(x) x^2)




```


## THE SET-UP BEFORE THE ALGO -- make sure to replace read.csv with the correct file path -- RUN THIS CODE CHUNK BEFORE RUNNING ANY OF THE HELPER FUNCTION INITIATING CODE CHUNKS BELOW
```{r}
## Re-arranged data
data_women_scores_2022_to_2023 <- read.csv("cleaned data/active_restricted_women_2023.csv") %>%  
  select(Country, FullName, Apparatus, Score) %>% 
  # first, making c(VT, VT1, VT2) all just VT, since they're all the same apparatus, just named different at different competitions
  mutate(Apparatus = ifelse(Apparatus %in% c("VT1", "VT2"), "VT", Apparatus))  %>%
  filter(!is.na(Score) & Score != 0) #dropping all NAs -- ask the team: should we also drop zeros? -> emily said yeah 11.13.2023 7 21pm


# this is the data that will feed into the algo
data_ready_for_algo <- data_women_scores_2022_to_2023 %>%
  group_by(Country, FullName, Apparatus) %>%
  summarise(Scores = list(Score), .groups = 'drop')




## Global Fixed Integers
minBBScoreIn_data_women_scores_2022_to_2023 <- min(data_women_scores_2022_to_2023$Score[data_women_scores_2022_to_2023$Apparatus == "BB"], na.rm = TRUE)
maxBBScoreIn_data_women_scores_2022_to_2023 <- max(data_women_scores_2022_to_2023$Score[data_women_scores_2022_to_2023$Apparatus == "BB"], na.rm = TRUE)

minFXScoreIn_data_women_scores_2022_to_2023 <- min(data_women_scores_2022_to_2023$Score[data_women_scores_2022_to_2023$Apparatus == "FX"], na.rm = TRUE)
maxFXScoreIn_data_women_scores_2022_to_2023 <- max(data_women_scores_2022_to_2023$Score[data_women_scores_2022_to_2023$Apparatus == "FX"], na.rm = TRUE)

minUBScoreIn_data_women_scores_2022_to_2023 <- min(data_women_scores_2022_to_2023$Score[data_women_scores_2022_to_2023$Apparatus == "UB"], na.rm = TRUE)
maxUBScoreIn_data_women_scores_2022_to_2023 <- max(data_women_scores_2022_to_2023$Score[data_women_scores_2022_to_2023$Apparatus == "UB"], na.rm = TRUE)

minVTScoreIn_data_women_scores_2022_to_2023 <- min(data_women_scores_2022_to_2023$Score[data_women_scores_2022_to_2023$Apparatus == "VT"], na.rm = TRUE)
maxVTScoreIn_data_women_scores_2022_to_2023 <- max(data_women_scores_2022_to_2023$Score[data_women_scores_2022_to_2023$Apparatus == "VT"], na.rm = TRUE)


## 2D Table of Global Fixed Integers
minAndMaxScores2DTable <- list(
    BB = list(
        min = minBBScoreIn_data_women_scores_2022_to_2023,
        max = maxBBScoreIn_data_women_scores_2022_to_2023
    ),
    FX = list(
        min = minFXScoreIn_data_women_scores_2022_to_2023,
        max = maxFXScoreIn_data_women_scores_2022_to_2023
    ),
    UB = list(
        min = minUBScoreIn_data_women_scores_2022_to_2023,
        max = maxUBScoreIn_data_women_scores_2022_to_2023
    ),
    VT = list(
        min = minVTScoreIn_data_women_scores_2022_to_2023,
        max = maxVTScoreIn_data_women_scores_2022_to_2023
    )
)


## TO BE FED INTO runOlympicsNTimes
allWomenBBParticipants <- data_ready_for_algo %>%
  select(Country, FullName, Apparatus) %>%
  unique() %>% 
  filter(Apparatus == "BB")

allWomenUBParticipants <- data_ready_for_algo %>%
  select(Country, FullName, Apparatus) %>%
  unique() %>% 
  filter(Apparatus == "UB")

allWomenFXParticipants <- data_ready_for_algo %>%
  select(Country, FullName, Apparatus) %>%
  unique() %>% 
  filter(Apparatus == "FX")

allWomenVTParticipants <- data_ready_for_algo %>%
  select(Country, FullName, Apparatus) %>%
  unique() %>% 
  filter(Apparatus == "VT")

allWomenBBParticipants <- allWomenBBParticipants %>%
  mutate(SimulationResults = lapply(seq_along(FullName), function(x) list()))

allWomenUBParticipants <- allWomenUBParticipants %>%
  mutate(SimulationResults = lapply(seq_along(FullName), function(x) list()))

allWomenFXParticipants <- allWomenFXParticipants %>%
  mutate(SimulationResults = lapply(seq_along(FullName), function(x) list()))

allWomenVTParticipants <- allWomenVTParticipants %>%
  mutate(SimulationResults = lapply(seq_along(FullName), function(x) list()))




## SD of BB Scores of all atheletes in the data (that will be the "nugget" when the there are three or fewer scores in an athlete x apparatus combination; the nugget will be used in estimateKernelDensity)
allBBScoresInTheData <- data_women_scores_2022_to_2023[data_women_scores_2022_to_2023$Apparatus == "BB", "Score"]
nuggetBB <- sd(allBBScoresInTheData)


## SD of UB Scores of all atheletes in the data (that will be the "nugget" when the there are three or fewer scores in an athlete x apparatus combination; the nugget will be used in estimateKernelDensity)
allUBScoresInTheData <- data_women_scores_2022_to_2023[data_women_scores_2022_to_2023$Apparatus == "UB", "Score"]
nuggetUB <- sd(allUBScoresInTheData)


## SD of FX Scores of all atheletes in the data (that will be the "nugget" when the there are three or fewer scores in an athlete x apparatus combination; the nugget will be used in estimateKernelDensity)
allFXScoresInTheData <- data_women_scores_2022_to_2023[data_women_scores_2022_to_2023$Apparatus == "FX", "Score"]
nuggetFX <- sd(allFXScoresInTheData)


## SD of VT Scores of all atheletes in the data (that will be the "nugget" when the there are three or fewer scores in an athlete x apparatus combination; the nugget will be used in estimateKernelDensity)
allVTScoresInTheData <- data_women_scores_2022_to_2023[data_women_scores_2022_to_2023$Apparatus == "VT", "Score"]
nuggetVT <- sd(allVTScoresInTheData)
```


## HELPER FUNCTION: createProperDataframe
```{r}
# Helper Function: createProperDataframe
# inputs are: "country code", "Athlete Name", "Apparatus (the two letters, like FX")
# output is a dataframe that is suitable for going in as input into the next step, aka creating estimated kernel densities

createProperDataframe = function(countryCode, athleteName, apparatusInitials){
  dataframeToReturn <- data_ready_for_algo %>% 
    filter(Country == countryCode, FullName == athleteName, Apparatus == apparatusInitials) %>% 
    select(Scores) %>% 
    unnest(Scores) %>% 
    unlist()
  
  apparatus <- apparatusInitials
  
  return(list(dataframeToReturn, apparatus))
}
```



## HELPER FUNCTION: estimateKernelDensity
```{r}
# Helper Function: estimateKernelDensity

# coming up with an estimate kernel density based on the inputs that are:
# 1. output of createProperDataframe = list(properDataframeCreatedForAthleteAndApparatusCombination, apparatus)
# 2. bandwidthValue (the bigger, the "smoother")

# output:
# dataframe of x and y coordinates --> coordinates of the estimated density function

estimateKernelDensity <- function(outputOfCreateProperDataframe, bandwidthValue){
  
  apparatusOfInterestHere = outputOfCreateProperDataframe[[2]]
  
  howManyScoresWeHaveForThatAthleteXApparatusCombination = length(outputOfCreateProperDataframe[[1]])
  
  #setting up appropriate "nugget"
  if (apparatusOfInterestHere == "BB"){
    if (howManyScoresWeHaveForThatAthleteXApparatusCombination < 4){
      nugget = nuggetBB*4
    }
    else{
      nugget = nuggetBB*2
    }
  }
  else if (apparatusOfInterestHere == "UB"){
    if (howManyScoresWeHaveForThatAthleteXApparatusCombination < 4){
      nugget = nuggetUB*4
    }
    else{
      nugget = nuggetUB*2
    }
  }
  else if (apparatusOfInterestHere == "FX"){
    if (howManyScoresWeHaveForThatAthleteXApparatusCombination < 4){
      nugget = nuggetFX*4
    }
    else{
      nugget = nuggetFX*2
    }
  }
  else{
    if (howManyScoresWeHaveForThatAthleteXApparatusCombination < 4){
      nugget = nuggetVT*4
    }
    else{
      nugget = nuggetVT*2
    }
  }
  

  
  kernelLowerLimit = max(minAndMaxScores2DTable$apparatusOfInterestHere$min - nugget, 0)
  kernelUpperLimit = min(minAndMaxScores2DTable$apparatusOfInterestHere$max + nugget, 15.7)
  
  
  almostToReturn <- bkde(x = outputOfCreateProperDataframe[[1]], kernel = "normal", canonical = FALSE, bandwidth = bandwidthValue, gridsize = 401L, range.x = c(kernelLowerLimit, kernelUpperLimit), truncate = TRUE)
  #range.x = c(kernelLowerLimit, kernelUpperLimit)
  dataframeToReturn <- data.frame(
    x = almostToReturn$x, 
    y = almostToReturn$y
  )
  
  return(dataframeToReturn)
}

```




## HELPER FUNCTION: createCDFfromKDEandDrawONEscore
```{r}
createCDFfromKDEandDrawONEscore <- function(dataframeReturnedByestimateKernelDensity){
  # Create a CDF from the KDE
  kde_y_cumsum <- cumsum(dataframeReturnedByestimateKernelDensity$y)
  cdf <- kde_y_cumsum / max(kde_y_cumsum)
  
  
  u <- runif(1)  # Generate uniform random number
  sampled_value <- dataframeReturnedByestimateKernelDensity$x[which.min(abs(cdf - u))]
  
  return(sampled_value)
  
  
}
```



## OVERALL ALGO: runOlympicsNTimes
```{r}
# OVERALL ALGO: runOlympicsNTimes
# input: n
# uses all sorts of helper functions


runOlympicsNTimes <- function(n, allWomenBBParticipants, allWomenFXParticipants, allWomenUBParticipants, allWomenVTParticipants){

  # 1. running the Women's BB n times
  BBParticipants_copied <- allWomenBBParticipants
  
  BBParticipants_copied$SimulationResults <- lapply(1:nrow(BBParticipants_copied), function(x) vector("list", n))
  for (nthOlympic in 1:n){
    
    # each nthOlympic-iteration of the Olympics, this is filling out the nthOlympic-index of each athlete's SimulationResults vector
    for (i in 1:nrow(BBParticipants_copied)) {
      row <- BBParticipants_copied[i, ]
      toAdd <- createCDFfromKDEandDrawONEscore(estimateKernelDensity(createProperDataframe(countryCode = row$Country, athleteName = row$FullName, apparatusInitials = row$Apparatus), 0.25))
    
      BBParticipants_copied[i, ]$SimulationResults[[1]][[nthOlympic]] <- toAdd
    }
    print(paste(nthOlympic, "th olympic done for Women's BB"))
    
  }
  
  #return(BBParticipants_copied)
  
  
    
  
  
  # 2. running the Women's FX n times
  FXParticipants_copied <- allWomenFXParticipants
  
  FXParticipants_copied$SimulationResults <- lapply(1:nrow(FXParticipants_copied), function(x) vector("list", n))
  for (nthOlympic in 1:n){
    
    # each nthOlympic-iteration of the Olympics, this is filling out the nthOlympic-index of each athlete's SimulationResults vector
    for (i in 1:nrow(FXParticipants_copied)) {
      row <- FXParticipants_copied[i, ]
      toAdd <- createCDFfromKDEandDrawONEscore(estimateKernelDensity(createProperDataframe(countryCode = row$Country, athleteName = row$FullName, apparatusInitials = row$Apparatus), 0.25))
    
      FXParticipants_copied[i, ]$SimulationResults[[1]][[nthOlympic]] <- toAdd
    }
    print(paste(nthOlympic, "th olympic done for Women's FX"))
    
  }
  
  #return(FXParticipants_copied)
  
  
  
  
  # 3. running the Women's UB n times
  UBParticipants_copied <- allWomenUBParticipants
  
  UBParticipants_copied$SimulationResults <- lapply(1:nrow(UBParticipants_copied), function(x) vector("list", n))
  for (nthOlympic in 1:n){
    
    # each nthOlympic-iteration of the Olympics, this is filling out the nthOlympic-index of each athlete's SimulationResults vector
    for (i in 1:nrow(UBParticipants_copied)) {
      row <- UBParticipants_copied[i, ]
      toAdd <- createCDFfromKDEandDrawONEscore(estimateKernelDensity(createProperDataframe(countryCode = row$Country, athleteName = row$FullName, apparatusInitials = row$Apparatus), 0.25))
    
      UBParticipants_copied[i, ]$SimulationResults[[1]][[nthOlympic]] <- toAdd
    }
    print(paste(nthOlympic, "th olympic done for Women's UB"))
    
  }
  
  #return(UBParticipants_copied)
  
  
  
  
  
  
  
  # 4. running the Women's VT n times
  VTParticipants_copied <- allWomenVTParticipants
  
  VTParticipants_copied$SimulationResults <- lapply(1:nrow(VTParticipants_copied), function(x) vector("list", n))
  for (nthOlympic in 1:n){
    
    # each nthOlympic-iteration of the Olympics, this is filling out the nthOlympic-index of each athlete's SimulationResults vector
    for (i in 1:nrow(VTParticipants_copied)) {
      row <- VTParticipants_copied[i, ]
      toAdd <- createCDFfromKDEandDrawONEscore(estimateKernelDensity(createProperDataframe(countryCode = row$Country, athleteName = row$FullName, apparatusInitials = row$Apparatus), 0.25))
    
      VTParticipants_copied[i, ]$SimulationResults[[1]][[nthOlympic]] <- toAdd
    }
    print(paste(nthOlympic, "th olympic done for Women's VT"))
    
  }
  
  #return(VTParticipants_copied)
  
  
  
  
  # RETURN A LIST CONTAINING FOUR DATAFRAMES
  return(list(BBResults = BBParticipants_copied, FXResults = FXParticipants_copied, UBResults = UBParticipants_copied, VTResults = VTParticipants_copied))
  
  
}

```

```{r}
runOlympicsNTimesParallel <- function(n, allWomenBBParticipants, allWomenFXParticipants, allWomenUBParticipants, allWomenVTParticipants){
  
  # Register the parallel backend to use multicore, with one less than the number of cores available
  no_cores <- detectCores() - 1
  cl <- makeCluster(no_cores)
  registerDoParallel(cl)

  # Export custom functions to each worker
  clusterExport(cl, varlist = c("createCDFfromKDEandDrawONEscore", "estimateKernelDensity", "createProperDataframe"))

  # Parallelized version of the Women's BB loop
  BBParticipants_copied <- allWomenBBParticipants
  BBParticipants_copied$SimulationResults <- lapply(1:nrow(BBParticipants_copied), function(x) vector("list", n))
  
  foreach(nthOlympic = 1:n, .combine = 'c', .multicombine = TRUE, .inorder = FALSE, .export = c("createCDFfromKDEandDrawONEscore", "estimateKernelDensity", "createProperDataframe")) %dopar% {
    for (i in 1:nrow(BBParticipants_copied)) {
      row <- BBParticipants_copied[i, ]
      BBParticipants_copied[i, ]$SimulationResults[[1]][[nthOlympic]] <- createCDFfromKDEandDrawONEscore(estimateKernelDensity(createProperDataframe(countryCode = row$Country, athleteName = row$FullName, apparatusInitials = row$Apparatus), 0.25))
    }
    cat(paste(nthOlympic, "th Olympic done for Women's BB\n"))
  }
  
  # 2. Parallelized version of the Women's FX loop
  FXParticipants_copied <- allWomenFXParticipants
  FXParticipants_copied$SimulationResults <- lapply(1:nrow(FXParticipants_copied), function(x) vector("list", n))
  
  foreach(nthOlympic = 1:n, .packages = c("packageNeededForFunctions")) %dopar% {
    for (i in 1:nrow(FXParticipants_copied)) {
      row <- FXParticipants_copied[i, ]
      FXParticipants_copied[i, ]$SimulationResults[[1]][[nthOlympic]] <- createCDFfromKDEandDrawONEscore(estimateKernelDensity(createProperDataframe(countryCode = row$Country, athleteName = row$FullName, apparatusInitials = row$Apparatus), 0.25))
    }
    cat(paste(nthOlympic, "th Olympic done for Women's FX\n"))
  }
  
  # 3. Parallelized version of the Women's UB loop
  UBParticipants_copied <- allWomenUBParticipants
  UBParticipants_copied$SimulationResults <- lapply(1:nrow(UBParticipants_copied), function(x) vector("list", n))
  
  foreach(nthOlympic = 1:n, .packages = c("packageNeededForFunctions")) %dopar% {
    for (i in 1:nrow(UBParticipants_copied)) {
      row <- UBParticipants_copied[i, ]
      UBParticipants_copied[i, ]$SimulationResults[[1]][[nthOlympic]] <- createCDFfromKDEandDrawONEscore(estimateKernelDensity(createProperDataframe(countryCode = row$Country, athleteName = row$FullName, apparatusInitials = row$Apparatus), 0.25))
    }
    cat(paste(nthOlympic, "th Olympic done for Women's UB\n"))
  }
  
  # 4. Parallelized version of the Women's VT loop
  VTParticipants_copied <- allWomenVTParticipants
  VTParticipants_copied$SimulationResults <- lapply(1:nrow(VTParticipants_copied), function(x) vector("list", n))
  
  foreach(nthOlympic = 1:n, .packages = c("packageNeededForFunctions")) %dopar% {
    for (i in 1:nrow(VTParticipants_copied)) {
      row <- VTParticipants_copied[i, ]
      VTParticipants_copied[i, ]$SimulationResults[[1]][[nthOlympic]] <- createCDFfromKDEandDrawONEscore(estimateKernelDensity(createProperDataframe(countryCode = row$Country, athleteName = row$FullName, apparatusInitials = row$Apparatus), 0.25))
    }
    cat(paste(nthOlympic, "th Olympic done for Women's VT\n"))
  }
  
  # Make sure to unregister the parallel backend after your function is done
  stopImplicitCluster()
  
  # RETURN A LIST CONTAINING FOUR DATAFRAMES
  return(list(BBResults = BBParticipants_copied, FXResults = FXParticipants_copied, UBResults = UBParticipants_copied, VTResults = VTParticipants_copied))
}



```




## Running the simulation
## Do not run this code, this code will run the simulations again

```{r}

# sanityCheck: runOlympicsNTimes
set.seed(120)
a = runOlympicsNTimes(1000, allWomenBBParticipants, allWomenFXParticipants, allWomenUBParticipants, allWomenVTParticipants)


```


## Code to get the mean from all simulations 

```{r}
aBB <- a$BBResults

aBB <- aBB %>% 
  mutate(mean = sapply(SimulationResults, function(x) mean(unlist(x))))


aUB <- a$UBResults

aUB <- aUB %>% 
  mutate(mean = sapply(SimulationResults, function(x) mean(unlist(x))))


aFX <- a$FXResults

aFX <- aFX %>% 
  mutate(mean = sapply(SimulationResults, function(x) mean(unlist(x))))


aVT <- a$VTResults

aVT <- aVT %>% 
  mutate(mean = sapply(SimulationResults, function(x) mean(unlist(x))))


```


## START OF ALL AROUND CODE 

## Code to load previous simulations

```{r}
# Read the CSV file into a dataframe
df <- read.csv("EZ Simulation Exports/women_BB_1000_EZ.csv", stringsAsFactors = FALSE)

# Convert the SimulationResults string to a list of numeric values
df$SimulationResults <- lapply(strsplit(df$SimulationResults, ",\\s*"), as.numeric)

aBB <- select(df, Country, FullName, Apparatus, SimulationResults, mean)

aBB <- aBB %>% 
  mutate(mean = sapply(SimulationResults, function(x) mean(unlist(x))))




# Read the CSV file into a dataframe
df <- read.csv("EZ Simulation Exports/women_UB_1000_EZ.csv", stringsAsFactors = FALSE)

# Convert the SimulationResults string to a list of numeric values
df$SimulationResults <- lapply(strsplit(df$SimulationResults, ",\\s*"), as.numeric)


aUB <- select(df, Country, FullName, Apparatus, SimulationResults, mean)

aUB <- aUB %>% 
  mutate(mean = sapply(SimulationResults, function(x) mean(unlist(x))))


# Read the CSV file into a dataframe
df <- read.csv("EZ Simulation Exports/women_FX_1000_EZ.csv", stringsAsFactors = FALSE)

# Convert the SimulationResults string to a list of numeric values
df$SimulationResults <- lapply(strsplit(df$SimulationResults, ",\\s*"), as.numeric)


aFX <- select(df, Country, FullName, Apparatus, SimulationResults, mean)

aFX <- aFX %>% 
  mutate(mean = sapply(SimulationResults, function(x) mean(unlist(x))))


# Read the CSV file into a dataframe
df <- read.csv("EZ Simulation Exports/women_VT_1000_EZ.csv", stringsAsFactors = FALSE)

# Convert the SimulationResults string to a list of numeric values
df$SimulationResults <- lapply(strsplit(df$SimulationResults, ",\\s*"), as.numeric)


aVT <- select(df, Country, FullName, Apparatus, SimulationResults, mean)

aVT <- aVT %>% 
  mutate(mean = sapply(SimulationResults, function(x) mean(unlist(x))))


```

## CALCULATING TOP 10 FOR EACH INDIVIDUAL APPARATUS

```{r}
## calculating the top three potential people in each individual event 

aBB_separated_data <- separate_columns(aBB, "SimulationResults", 1000)

aBB_Top_Three <- aBB_separated_data %>% 
  filter(Country == "USA") %>% 
  arrange(desc(avg_result)) %>% 
  select(Country, FullName, mean, avg_result, Apparatus) %>% 
  slice(1:10)


aFX_separated_data <- separate_columns(aFX, "SimulationResults", 1000)

aFX_Top_Three <- aFX_separated_data %>% 
  filter(Country == "USA") %>% 
  arrange(desc(avg_result)) %>% 
  select(Country, FullName, mean, avg_result, Apparatus) %>% 
  slice(1:10)

aUB_separated_data <- separate_columns(aUB, "SimulationResults", 1000)

aUB_Top_Three <- aUB_separated_data %>% 
  filter(Country == "USA") %>% 
  arrange(desc(avg_result)) %>% 
  select(Country, FullName, mean, avg_result, Apparatus) %>% 
  slice(1:10)

aVT_separated_data <- separate_columns(aVT, "SimulationResults", 1000)

aVT_Top_Three <- aVT_separated_data %>% 
  filter(Country == "USA") %>% 
  arrange(desc(avg_result)) %>% 
  select(Country, FullName, mean, avg_result, Apparatus) %>% 
  slice(1:10)


```

## CALCULATING TOP 5 FOR ALL AROUND

### Creating a new dataframe of AllAround results 

```{r}
# Get the unique list of FullNames from all dataframes
all_names <- unique(c(aBB$FullName, aUB$FullName, aFX$FullName, aVT$FullName))

# Function to add missing entries
add_missing_entries <- function(df, names, apparatus) {
  # Names that are missing in the dataframe
  missing_names <- setdiff(names, df$FullName)
  
  # Create missing entries with the specified values
  missing_entries <- data.frame(
    Country = rep('USA', length(missing_names)),
    FullName = missing_names,
    Apparatus = rep(apparatus, length(missing_names)),
    SimulationResults = I(replicate(length(missing_names), list(rep(0, 1000)))),
    mean = rep(0, length(missing_names))

  )
  
  # Combine the original dataframe with the missing entries
  rbind(df, missing_entries)
}

# Add missing entries to each dataframe
aBB <- add_missing_entries(aBB, all_names, 'BB')
aUB <- add_missing_entries(aUB, all_names, 'UB')
aFX <- add_missing_entries(aFX, all_names, 'FX')
aVT <- add_missing_entries(aVT, all_names, 'VT')

```


```{r}
# Using left_join to ensure all names are included from each dataframe.

merged_df <- aBB %>%
  left_join(aUB, by = "FullName") %>%
  left_join(aFX, by = "FullName") %>%
  left_join(aVT, by = "FullName")

# Rename the SimulationResults columns to avoid name clashes
names(merged_df)[names(merged_df) == 'SimulationResults.x'] <- 'SimulationResultsBB'
names(merged_df)[names(merged_df) == 'SimulationResults.y'] <- 'SimulationResultsUB'
names(merged_df)[names(merged_df) == 'SimulationResults.x.x'] <- 'SimulationResultsFX'
names(merged_df)[names(merged_df) == 'SimulationResults.y.y'] <- 'SimulationResultsVT'

# create a new SimulationResults column which is a list of sums of corresponding elements.

# Function to sum the elements of the simulation results
sum_simulation_results <- function(bb, ub, fx, vt) {
  mapply(sum, bb, ub, fx, vt) # Sum corresponding elements
}

# Apply the function to each row using rowwise and then mutate to create the new column
merged_df <- merged_df %>%
  rowwise() %>%
  mutate(BB = list(SimulationResultsBB), UB = list(SimulationResultsUB), FX = list(SimulationResultsFX), VT = list(SimulationResultsVT))

# Create the final dataframe with required columns
aAllAround <- merged_df %>%
  select(Country = Country.x, FullName, BB, UB, FX, VT) %>% 
  filter(!all(sapply(BB, function(x) all(x == 0)))) %>% 
    filter(!all(sapply(UB, function(x) all(x == 0)))) %>% 
    filter(!all(sapply(FX, function(x) all(x == 0)))) %>% 
    filter(!all(sapply(VT, function(x) all(x == 0))))

calculate_all_around <- function(data) {
  # Use rowwise to apply the function to each row
  AllAround <- data %>%
    rowwise() %>%
    mutate(
      # Use purrr::pmap_dbl to sum the nth element of each list column
      AllAround = list(pmap_dbl(list(BB, UB, FX, VT), ~sum(c(...))))
    )
  
  return(AllAround)
}

aAllAround1 <- calculate_all_around(aAllAround) 

aAllAround1 <- aAllAround1 %>% 
  unnest_wider(AllAround, names_sep = "_")
  

## helper function to transform scores into relevant medals
transform_values <- function(column) {
  ranks <- min_rank(-column)  # Rank in descending order, ties are handled so that people with the same score are given the same medal 
  result <- ifelse(ranks == 1, 3, ifelse(ranks == 2, 2, ifelse(ranks == 3, 1, 0)))
  return(result)
}

separate_columns <- function(data, list_column_name, num_columns) {
  
  # Bind the result matrix with the original data frame, excluding the original list column
  result_data <- mutate_at(data, vars(starts_with(list_column_name)), transform_values)
  
  result_data$avg_result_allAround <- rowMeans(select(result_data, starts_with(list_column_name)))

  return(result_data)
}
```



```{r}
aAllAround2 <- separate_columns(aAllAround1, "AllAround", 1000)

aAllAround2 <- aAllAround2 %>% 
  select(Country, FullName, avg_result_allAround) %>% 
  arrange(desc(avg_result_allAround)) %>% 
  slice(1:26)

write.csv(aAllAround2, "Women_All_Around_Top.csv")

aAllAround_TopUSA <- aAllAround2 %>% 
  select(Country, FullName, avg_result_allAround) %>% 
  arrange(desc(avg_result_allAround)) %>% 
  filter(Country == "USA")

# write.csv(aAllAround_TopUSA, "Women_aAllAround_TopUSA.csv")

```


## USING A DATA FRAME THAT COMPILED THE ABOVE TOP PERFORMER DATAFRAMES

```{r}

Competitors <- read.csv("EZ Simulation Exports/Women_Top7_MedalScores.csv")

# Create a vector of all unique FullNames across the dataframes
all_fullnames <- unique(Competitors$Name)

# Initialize an empty dataframe to store the combinations and results
result_df <- data.frame()

# Iterate through all combinations of 5 FullName values
for (i in 1:length(all_fullnames)) {
  for (j in (i+1):length(all_fullnames)) {
    for (k in (j+1):length(all_fullnames)) {
      for (l in (k+1):length(all_fullnames)) {
        for (m in (l+1):length(all_fullnames)) {
          # Extract the FullName values for the combination
          combo <- c(all_fullnames[i], all_fullnames[j], all_fullnames[k], all_fullnames[l], all_fullnames[m])
          
          # Filter the dataframes for the specific 
          bb_result <- sum(head(subset(Competitors, Name %in% combo)[order(-subset(Competitors, Name %in% combo)$BB), ]$BB, 2))
          fx_result <- sum(head(subset(Competitors, Name %in% combo)[order(-subset(Competitors, Name %in% combo)$FX), ]$FX, 2))
          ub_result <- sum(head(subset(Competitors, Name %in% combo)[order(-subset(Competitors, Name %in% combo)$UB), ]$UB, 2))
          vt_result <- sum(head(subset(Competitors, Name %in% combo)[order(-subset(Competitors, Name %in% combo)$VT), ]$VT, 2))
          aa_result <- sum(head(subset(Competitors, Name %in% combo)[order(-subset(Competitors, Name %in% combo)$AA), ]$AA, 2))

          # Create a new row with the combination and results
          new_row <- data.frame(Combo = paste(combo, collapse = ", "),
                                BB_Result = bb_result,
                                FX_Result = fx_result,
                                UB_Result = ub_result,
                                VT_Result = vt_result,
                                AA_Result = aa_result)
          
          # Append the new row to the result dataframe
          result_df <- rbind(result_df, new_row)
        }
      }
    }
  }
}

# Display the resulting dataframe with all combinations and results
result_df$Total_Result <- rowSums(result_df[, c("BB_Result", "FX_Result", "UB_Result", "VT_Result", "AA_Result")])

results_top5 <- result_df %>% 
  arrange(desc(Total_Result)) %>% 
  slice(1:5)

#write.csv(results_top5, "EZ Simulation Exports/Women_Final_Team_Config.csv")
```




















### INDIVIDUAL EVENTS START HERE




```{r}

## helper function to transform scores into relevant medals
transform_values <- function(column) {
  ranks <- min_rank(-column)  # Rank in descending order, ties are handled so that people with the same score are given the same medal 
  result <- ifelse(ranks == 1, 3, ifelse(ranks == 2, 2, ifelse(ranks == 3, 1, 0)))
  return(result)
}

separate_columns <- function(data, list_column_name, num_columns) {
  # Create empty data frame to store the separated columns
  result_matrix <- matrix(NA, nrow = nrow(data), ncol = num_columns)
  colnames(result_matrix) <- paste(list_column_name, seq_len(num_columns), sep = "_")
  
  # Loop through each row and separate the nested list into columns
  for (i in seq_len(nrow(data))) {
    nested_list <- data[[list_column_name]][i]
    
    # checking if list is empty (numeric(0))
    if (is.na(data[["mean"]][i])){
      result_matrix[i, ] <- 0
    }
    
    else {
      # Assign the values to the corresponding columns in the result matrix
      result_matrix[i, ] <- unlist(nested_list)
    }
    
  }
  
  # Bind the result matrix with the original data frame, excluding the original list column
  result_data <- cbind(data[, -which(names(data) == list_column_name)], result_matrix)
  result_data <- mutate_at(result_data, vars(starts_with(list_column_name)), transform_values)
  
  result_data$avg_result <- rowMeans(select(result_data, starts_with(list_column_name)))

  return(result_data)
}
```








## Convert list to string type
```{r}
BBResults <- aBB
#Convert all list columns in BBResults to character strings
BBResults[] <- lapply(BBResults, function(x) {
 if (is.list(x)) {
   sapply(x, toString)
 } else {
   x
 }
})


UBResults <- aUB
#Convert all list columns in BBResults to character strings
UBResults[] <- lapply(UBResults, function(x) {
 if (is.list(x)) {
   sapply(x, toString)
 } else {
   x
 }
})


FXResults <- aFX
#Convert all list columns in BBResults to character strings
FXResults[] <- lapply(FXResults, function(x) {
 if (is.list(x)) {
   sapply(x, toString)
 } else {
   x
 }
})
#Now save the modified data frame to a CSV file

VTResults <- aVT
#Convert all list columns in BBResults to character strings
VTResults[] <- lapply(VTResults, function(x) {
 if (is.list(x)) {
   sapply(x, toString)
 } else {
   x
 }
})

```


```{r}
write.csv(result_df, file = "simluation_results_young/women_medal_expectation.csv")

write.csv(aBB_Top_Three, file = "simluation_results_young/women_aBB_Top_Three.csv")
write.csv(aUB_Top_Three, file = "simluation_results_young/women_aUB_Top_Three.csv")
write.csv(aFX_Top_Three, file = "simluation_results_young/women_aFX_Top_Three.csv")
write.csv(aVT_Top_Three, file = "simluation_results_young/women_aVT_Top_Three.csv")
write.csv(aAllAround_Top_Three, file = "simluation_results_young/women_aAllAround_Top_Three.csv")


```
## Save Simulation Results

```{r}


write.csv(all_aroud_finalists, file = "/simulation_results/women_all_around_finalists_1000_EZ.csv")




write.csv(aBB_separated_data, file = "women_aBB_Weighted_Medals.csv")
write.csv(aUB_separated_data, file = "women_aUB_Weighted_Medals.csv")
write.csv(aFX_separated_data, file = "women_aFX_Weighted_Medals.csv")
write.csv(aVT_separated_data, file = "women_aVT_Weighted_Medals.csv")
write.csv(aVT_separated_data, file = "women_aVT_Weighted_Medals.csv")


write.csv(BBResults, file = "women_BB_1000_EZ.csv")
write.csv(UBResults, file = "women_UB_1000_EZ.csv")
write.csv(FXResults, file = "women_FX_1000_EZ.csv")
write.csv(VTResults, file = "women_VT_1000_EZ.csv")
write.csv(VTResults, file = "women_VT_1000_EZ.csv")



```



